{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonathas-1993/Topicos_UFAM/blob/main/2_TextVectorization_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código para vetorização usando a biblioteca Keras. Na etapa de padronização, o código abaixo coloca todas as palavras em minúsculo e retira os sinais de pontuação."
      ],
      "metadata": {
        "id": "W-ykzcEAPVIX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHVw3n8FPQED"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "text_vectorization = TextVectorization(\n",
        "        output_mode='int',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para indexar um \"corpo de texto\" (text corpus) usa-se a função adapt"
      ],
      "metadata": {
        "id": "pkgKxjBsPyo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [\n",
        "\"I write, erase, rewrite\",\n",
        "\"Erase again, and then\",\n",
        "\"A poppy blooms.\",\n",
        "]\n",
        "text_vectorization.adapt(dataset)\n"
      ],
      "metadata": {
        "id": "mLDTy95AP-Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "É possível recuperar o vocabulário com a função get_vocabulary().As duas primeiras entradas no vocabulário são o token de máscara (índice 0) e o token OOV (índice 1). As entradas são listadas por frequência de ocorrência. Assim, \"the\" or \"a\" vêm smpre primeiro em um texto maior."
      ],
      "metadata": {
        "id": "FLYw3xneRIsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdb5sl5PR3iF",
        "outputId": "a6a465de-b3fa-466f-bb9d-2eec3db4b506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'erase',\n",
              " 'write',\n",
              " 'then',\n",
              " 'rewrite',\n",
              " 'poppy',\n",
              " 'i',\n",
              " 'blooms',\n",
              " 'and',\n",
              " 'again',\n",
              " 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemplo de codificação"
      ],
      "metadata": {
        "id": "muaI9g8pSNUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_sentence =\"I write, rewrite, and still rewrite again\"\n",
        "encoded_sentence = text_vectorization(test_sentence)\n",
        "print(encoded_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGuZdAc6SgIz",
        "outputId": "bfb331ad-d830-473a-ae76-982765167d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemplo de decodificação"
      ],
      "metadata": {
        "id": "h9swDYkLSskS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "inverse_vocab = dict(enumerate(vocabulary))\n",
        "decoded_sentence =\" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n",
        "print(decoded_sentence)\n",
        "print(vocabulary)\n",
        "print(inverse_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njcp5Rj4Svgc",
        "outputId": "0920bfd6-8307-4df5-b761-a57b8054f834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i write rewrite and [UNK] rewrite again\n",
            "['', '[UNK]', 'erase', 'write', 'then', 'rewrite', 'poppy', 'i', 'blooms', 'and', 'again', 'a']\n",
            "{0: '', 1: '[UNK]', 2: 'erase', 3: 'write', 4: 'then', 5: 'rewrite', 6: 'poppy', 7: 'i', 8: 'blooms', 9: 'and', 10: 'again', 11: 'a'}\n"
          ]
        }
      ]
    }
  ]
}