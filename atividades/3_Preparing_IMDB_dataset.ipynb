{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonathas-1993/Topicos_UFAM/blob/main/3_Preparing_IMDB_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw5Gnl2TC6Ma"
      },
      "source": [
        "Preparando a base IMDM para processamento por Bag of Words, sequences and transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RMAOQ6wDKtP"
      },
      "source": [
        "Vamos começar baixando a base de dados da página de Andrew Maas de Standofrd e descomprimindo ela."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyOZOLmvC3TT",
        "outputId": "92be58e7-05cf-4a37-9daf-ced9ee135b24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  22.0M      0  0:00:03  0:00:03 --:--:-- 22.0M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz # opção -O salva arquivo com o mesmo nome no\n",
        "!tar -xf aclImdb_v1.tar.gz                                               # diretório atual. opção - o permite especificar\n",
        "                                                                         # outro nome"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_00lykS2HFwS"
      },
      "source": [
        "For instance, the train/pos/ directory contains a set of 12,500 text files, each of which contains the text body of a positive-sentiment movie review to be used as training data.The negative-sentiment reviews live in the “neg” directories. In total, there are 25,000 text files for training and another 25,000 for testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsRoT_c0HV-q"
      },
      "source": [
        "Take a look at the content of a few of these text files. Whether you’re working withtext data or image data, remember to alwaysinspect what your data looks like beforeyou dive into modeling it. It will ground your intuition about what your model is actu-\n",
        "ally doing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmKWaphwHLuG",
        "outputId": "74083b2d-6b9c-46af-a2a1-afa9844c4ff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ],
      "source": [
        "!cat aclImdb/train/pos/4077_10.txt      # o comando  cat mostra o conteúdo de um arquivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv01hcqGNL6R"
      },
      "source": [
        "There’s also a train/unsup subdirectoryin there, which we don’t need. Let’s delete it: (não pode ter outras pastas além\n",
        "daquelas contendo os exemplos das classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLga2lNVNQIL"
      },
      "outputs": [],
      "source": [
        "!rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cryg1Y_bH43T"
      },
      "source": [
        "Next, let’s prepare a validation set by setting apart 20% of the training text\n",
        "\n",
        "1.   Item de lista\n",
        "2.   Item de lista\n",
        "\n",
        "files in a\n",
        "new directory, aclImdb/val:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqLzNbK9H575"
      },
      "outputs": [],
      "source": [
        "import os, pathlib, shutil, random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYDHGscTH9W_"
      },
      "outputs": [],
      "source": [
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir /\"val\"\n",
        "train_dir = base_dir /\"train\"\n",
        "for category in(\"neg\",\"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)           #Shuffle the list of training files using a seed, to ensure we get\n",
        "                                                 # the same validation set every time we run the code.\n",
        "    num_val_samples = int(0.2* len(files))       #Take 20% of the training files to use for validation\n",
        "    val_files=files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "      shutil.move(train_dir/category/fname,      #The shutil module offers a number of high-level operations on files\n",
        "                  val_dir/category/fname)        #Move the files to aclImdb/val/neg and aclImdb/val/pos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq1BQCzzMlzr"
      },
      "source": [
        "Let’s create threeDatasetobjects for training, validation, and testing:\n",
        "\n",
        "*   Item de lista\n",
        "*   Item de lista\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc3c_u-8Mmqn"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "batch_size=32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3piNijTwMt-5",
        "outputId": "6a3d472d-93f2-4c94-949f-e3f735baa4a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = keras.utils.text_dataset_from_directory(    #main_directory/\n",
        "\"aclImdb/train\", batch_size=batch_size                 #...class_a/\n",
        ")                                                      #......a_text_1.txt\n",
        "val_ds = keras.utils.text_dataset_from_directory(      #......a_text_2.txt\n",
        "\"aclImdb/val\", batch_size=batch_size                   #...class_b/\n",
        ")                                                      #......b_text_1.txt\n",
        "test_ds = keras.utils.text_dataset_from_directory(     #......b_text_2.txt\n",
        "\"aclImdb/test\", batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6Mi13KsxIq3v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKqLy6LkO8FO"
      },
      "source": [
        "Running this line should output “Found 20000 files belonging to 2 classes”; if you see “Found 70000 files belonging to 3 classes,” it means you forgot to delete the aclImdb/train/unsup directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0JbMlOrPimr"
      },
      "source": [
        "These datasets yield inputs that are TensorFlow tf.string tensors and targets that are\n",
        "int32 tensors encoding the value “0” or “1.”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k69HZEdNP5wS"
      },
      "source": [
        "Displaying the shapes and dtypes of the first batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqUalXxlPjoq",
        "outputId": "75cf728b-1968-4b59-82e1-bd99a175e4d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b\"Okay, that was a pretty damn good episode. Much better than the credit it receives.<br /><br />The camera work is splendid. Best yet. I love that final shot. The atmosphere is fantastic, the costumes are great and the guest cast (minus the helpless victims) is strong. <br /><br />What I don't like about this episode is that many things that are left unexplained. why does it change sex? what's the purpose? and they're aliens? what kind? why were they never shown again in the later mythology?<br /><br />I'm giving this episode a high THREE stars. One of my favorites yet, but the plot holes bother me. Still... not gonna let it ruin my entertainment.\", shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID7fT7voYwIo"
      },
      "source": [
        "\"********************************************************\"-\n",
        "***O código a Seguir refere-se a \"*TextVectorization_bag_unigram\n",
        "\"********************************************************\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uLYPS1eZcLE"
      },
      "source": [
        "Limit the vocabulary to the 20,000 most frequent words.Otherwise we’d be indexing every word in the training data—potentially tens of thousands of terms that only occur once or twice and thus aren’t informative. In general, 20,000 is the right vocabulary size for text classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sezOEM6CZ_Ez"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OY-NdcvvZC_e"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",                #Encode the output tokens as multi-hot binary vectors.\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkWsJ8_rUZ0K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ayn0PnOUaLh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAVhhYzofMKy"
      },
      "source": [
        ":map(\n",
        "    map_func, num_parallel_calls=None, deterministic=None, name=None\n",
        ")\n",
        "Maps map_func across the elements of this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvoqYCCjadwh"
      },
      "outputs": [],
      "source": [
        "text_only_train_ds = train_ds.map(lambda x, y: x)  #Prepare a dataset that only yields raw text inputs (no labels).\n",
        "text_vectorization.adapt(text_only_train_ds) #Use that dataset to index the dataset vocabulary via the adapt() method\n",
        "\n",
        "binary_1gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),num_parallel_calls=4) #Prepare processed versions of our training,\n",
        "binary_1gram_val_ds = val_ds.map(                                 #validation, and test dataset.\n",
        "    lambda x, y: (text_vectorization(x), y),num_parallel_calls=4) #Make sure to specify num_parallel_calls\n",
        "binary_1gram_test_ds = test_ds.map(                               #to leverage multiple CPU cores.\n",
        "    lambda x, y: (text_vectorization(x), y),num_parallel_calls=4) # o resultado de lambda mapeia x,y em vetor multi-hot,y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn-URID5grfm"
      },
      "source": [
        "Inspecting the output of our binary unigram dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV6lSB4Agsb-",
        "outputId": "eb028ffe-5ddd-4a97-cbfe-531cce64e7c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs.shape: (32, 20000)\n",
            "inputs.dtype: <dtype: 'int64'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor([1 1 1 ... 0 0 0], shape=(20000,), dtype=int64)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in binary_1gram_train_ds:\n",
        "  print(\"inputs.shape:\", inputs.shape)   #Inputs are batches of 20,000-dimensional vectors.\n",
        "  print(\"inputs.dtype:\", inputs.dtype)   #These vectors consistentirely of ones and zeros.\n",
        "  print(\"targets.shape:\", targets.shape)\n",
        "  print(\"targets.dtype:\", targets.dtype)\n",
        "  print(\"inputs[0]:\", inputs[0])\n",
        "  print(\"targets[0]:\", targets[0])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-8Ztl9Xix3x"
      },
      "source": [
        "Criando um modelo simples de classificação com uma camada escondida e uma camada de saída. Funções ReLU e sigmmoid. Usa Dropout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdBwJGPni-3N"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4wKcH6WSdWy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGHnjpwPjXRJ"
      },
      "outputs": [],
      "source": [
        "def get_model(max_tokens=20000, hidden_dim=16):\n",
        "    inputs = keras.Input(shape=(max_tokens,))\n",
        "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUZG7YLzju6W"
      },
      "source": [
        "Treinando o modelo (We call cache() on the datasets to cache them in memory: this way, we will only do the preprocessing once, during the first epoch, and we’ll reuse the preprocessed texts for the following epochs. This can only be done if the data is small enough to fit in memory.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "DuDm32M8j1Xa",
        "outputId": "354048de-b897-44bc-faf9-b4ad9f329818"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,016</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │         \u001b[38;5;34m320,016\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 798ms/step - accuracy: 0.7817 - loss: 0.4779 - val_accuracy: 0.8870 - val_loss: 0.2856\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "File format not supported: filepath=/tmp/checkpoint. Keras 3 only supports V3 `.keras` and `.weights.h5` files, or legacy V1/V2 `.h5` files.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5c2a283be107>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m model.fit(binary_1gram_train_ds,\n\u001b[1;32m     11\u001b[0m validation_data=binary_1gram_val_ds.cache(),epochs=1,callbacks=[model_checkpoint_callback])\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(model, filepath, skip_mismatch, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mlegacy_h5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0;34mf\"File format not supported: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m\"Keras 3 only supports V3 `.keras` and `.weights.h5` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File format not supported: filepath=/tmp/checkpoint. Keras 3 only supports V3 `.keras` and `.weights.h5` files, or legacy V1/V2 `.h5` files."
          ]
        }
      ],
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/tmp/checkpoint.weights.h5',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "model.fit(binary_1gram_train_ds,\n",
        "validation_data=binary_1gram_val_ds.cache(),epochs=1,callbacks=[model_checkpoint_callback])\n",
        "model.load_weights(checkpoint_filepath)\n",
        "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FztIREmpEoV"
      },
      "source": [
        "\"********************************************************\"-\n",
        "****O código a Seguir refere-se a \"*TextVectorization_bag_bigram\"****\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnWT3tghpRiC"
      },
      "source": [
        "TheTextVectorizationlayer can be configured to return arbitrary N-grams: bigrams,trigrams, etc. Just pass anngrams=Nargument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUhJNjwKpHDl"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwzTwqVppbd5"
      },
      "source": [
        "Training and testing the binary bigram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4IAvWsapcgk",
        "outputId": "aaadc179-d036-4814-c811-69f96ac2a46b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320033 (1.22 MB)\n",
            "Trainable params: 320033 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 4s 5ms/step - loss: 0.4156 - accuracy: 0.8248 - val_loss: 0.2975 - val_accuracy: 0.8830\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2729 - accuracy: 0.9000 - val_loss: 0.2925 - val_accuracy: 0.8902\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2392 - accuracy: 0.9143 - val_loss: 0.3081 - val_accuracy: 0.8880\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2293 - accuracy: 0.9233 - val_loss: 0.3264 - val_accuracy: 0.8876\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2148 - accuracy: 0.9282 - val_loss: 0.3380 - val_accuracy: 0.8890\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2083 - accuracy: 0.9324 - val_loss: 0.3582 - val_accuracy: 0.8874\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2059 - accuracy: 0.9347 - val_loss: 0.3689 - val_accuracy: 0.8856\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1964 - accuracy: 0.9371 - val_loss: 0.3869 - val_accuracy: 0.8870\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1978 - accuracy: 0.9380 - val_loss: 0.3866 - val_accuracy: 0.8868\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1961 - accuracy: 0.9398 - val_loss: 0.4072 - val_accuracy: 0.8876\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.2902 - accuracy: 0.8849\n",
            "Test acc: 0.885\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)  #Prepare a dataset that only yields raw text inputs (no labels).\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),num_parallel_calls=4)\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),num_parallel_calls=4)\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),num_parallel_calls=4)\n",
        "model = get_model()\n",
        "model.summary()\n",
        "\n",
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/tmp/checkpoint.weights.h5',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "#callbacks = [\n",
        "#    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",save_best_only=True)\n",
        "#]\n",
        "\n",
        "model.fit(binary_2gram_train_ds.cache(),\n",
        "validation_data=binary_2gram_val_ds.cache(),\n",
        "epochs=1,callbacks=[model_checkpoint_callback]\n",
        ")\n",
        "#model = keras.models.load_model(\"binary_2gram.keras\")\n",
        "model.load_weights(checkpoint_filepath)\n",
        "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS1obpoWexER",
        "outputId": "73461600-8b83-4e83-b5c4-e533f54783be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 1s 3ms/step - loss: 0.2925 - accuracy: 0.8902\n",
            "Test acc: 0.890\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test acc: {model.evaluate(binary_2gram_val_ds)[1]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2Mp257fdrov"
      },
      "source": [
        "***Tarefa para os alunos: implementar com tf_idf**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}