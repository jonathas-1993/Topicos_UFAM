{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonathas-1993/Topicos_UFAM/blob/main/atividades/3_Preparing_IMDB_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw5Gnl2TC6Ma"
      },
      "source": [
        "Preparando a base IMDM para processamento por Bag of Words, sequences and transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RMAOQ6wDKtP"
      },
      "source": [
        "Vamos começar baixando a base de dados da página de Andrew Maas de Standofrd e descomprimindo ela."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyOZOLmvC3TT",
        "outputId": "5a2ae13b-b62a-42ad-8dd1-a807122ece14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  4156k      0  0:00:19  0:00:19 --:--:-- 6256k\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz # opção -O salva arquivo com o mesmo nome no\n",
        "!tar -xf aclImdb_v1.tar.gz                                               # diretório atual. opção - o permite especificar\n",
        "                                                                         # outro nome"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_00lykS2HFwS"
      },
      "source": [
        "For instance, the train/pos/ directory contains a set of 12,500 text files, each of which contains the text body of a positive-sentiment movie review to be used as training data.The negative-sentiment reviews live in the “neg” directories. In total, there are 25,000 text files for training and another 25,000 for testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsRoT_c0HV-q"
      },
      "source": [
        "Take a look at the content of a few of these text files. Whether you’re working withtext data or image data, remember to alwaysinspect what your data looks like beforeyou dive into modeling it. It will ground your intuition about what your model is actu-\n",
        "ally doing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmKWaphwHLuG",
        "outputId": "0cc8a97d-ff51-4d6d-bfa6-f5687759e25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ],
      "source": [
        "!cat aclImdb/train/pos/4077_10.txt      # o comando  cat mostra o conteúdo de um arquivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv01hcqGNL6R"
      },
      "source": [
        "There’s also a train/unsup subdirectoryin there, which we don’t need. Let’s delete it: (não pode ter outras pastas além\n",
        "daquelas contendo os exemplos das classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZLga2lNVNQIL"
      },
      "outputs": [],
      "source": [
        "!rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cryg1Y_bH43T"
      },
      "source": [
        "Next, let’s prepare a validation set by setting apart 20% of the training text\n",
        "\n",
        "1.   Item de lista\n",
        "2.   Item de lista\n",
        "\n",
        "files in a\n",
        "new directory, aclImdb/val:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XqLzNbK9H575"
      },
      "outputs": [],
      "source": [
        "import os, pathlib, shutil, random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MYDHGscTH9W_"
      },
      "outputs": [],
      "source": [
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir /\"val\"\n",
        "train_dir = base_dir /\"train\"\n",
        "for category in(\"neg\",\"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)           #Shuffle the list of training files using a seed, to ensure we get\n",
        "                                                 # the same validation set every time we run the code.\n",
        "    num_val_samples = int(0.2* len(files))       #Take 20% of the training files to use for validation\n",
        "    val_files=files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "      shutil.move(train_dir/category/fname,      #The shutil module offers a number of high-level operations on files\n",
        "                  val_dir/category/fname)        #Move the files to aclImdb/val/neg and aclImdb/val/pos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq1BQCzzMlzr"
      },
      "source": [
        "Let’s create threeDatasetobjects for training, validation, and testing:\n",
        "\n",
        "*   Item de lista\n",
        "*   Item de lista\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mc3c_u-8Mmqn"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "batch_size=32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3piNijTwMt-5",
        "outputId": "c9c389a9-bd10-440b-d865-50979d7e074a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = keras.utils.text_dataset_from_directory(    #main_directory/\n",
        "\"aclImdb/train\", batch_size=batch_size                 #...class_a/\n",
        ")                                                      #......a_text_1.txt\n",
        "val_ds = keras.utils.text_dataset_from_directory(      #......a_text_2.txt\n",
        "\"aclImdb/val\", batch_size=batch_size                   #...class_b/\n",
        ")                                                      #......b_text_1.txt\n",
        "test_ds = keras.utils.text_dataset_from_directory(     #......b_text_2.txt\n",
        "\"aclImdb/test\", batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6Mi13KsxIq3v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKqLy6LkO8FO"
      },
      "source": [
        "Running this line should output “Found 20000 files belonging to 2 classes”; if you see “Found 70000 files belonging to 3 classes,” it means you forgot to delete the aclImdb/train/unsup directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0JbMlOrPimr"
      },
      "source": [
        "These datasets yield inputs that are TensorFlow tf.string tensors and targets that are\n",
        "int32 tensors encoding the value “0” or “1.”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k69HZEdNP5wS"
      },
      "source": [
        "Displaying the shapes and dtypes of the first batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqUalXxlPjoq",
        "outputId": "021ca864-b4a6-4e27-d308-614e5f5ea197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b\"Essentially a story of man versus nature, this film has beautiful cinematography, the lush jungles of Ceylon and the presence of Elizabeth Taylor but the film really never gets going. Newlwed Taylor is ignored and neglected by her husband and later is drawn to the plantation's foreman, played by Dana Andrews. The plantation is under the spell of owner Peter Finch's late father whose ghost casts a pall over Elephant Walk that becomes a major point of contention between Taylor and Finch. The elephants are determined to reclaim their traditional path to water that was blocked when the mansion was built across their right-of-way. The beasts go on a rampage and provides the best moments of action in the picture. Taylor and Andrews have some good moments as she struggles to remain a faithful wife in spite of he marital difficulties with Finch.\", shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds:\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "    print(\"inputs[0]:\", inputs[0])\n",
        "    print(\"targets[0]:\", targets[0])\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID7fT7voYwIo"
      },
      "source": [
        "\"********************************************************\"-\n",
        "***O código a Seguir refere-se a \"*TextVectorization_bag_unigram\n",
        "\"********************************************************\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uLYPS1eZcLE"
      },
      "source": [
        "Limit the vocabulary to the 20,000 most frequent words.Otherwise we’d be indexing every word in the training data—potentially tens of thousands of terms that only occur once or twice and thus aren’t informative. In general, 20,000 is the right vocabulary size for text classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sezOEM6CZ_Ez"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OY-NdcvvZC_e"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",                #Encode the output tokens as multi-hot binary vectors.\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zkWsJ8_rUZ0K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2Ayn0PnOUaLh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAVhhYzofMKy"
      },
      "source": [
        ":map(\n",
        "    map_func, num_parallel_calls=None, deterministic=None, name=None\n",
        ")\n",
        "Maps map_func across the elements of this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yvoqYCCjadwh"
      },
      "outputs": [],
      "source": [
        "text_only_train_ds = train_ds.map(lambda x, y: x)  #Prepare a dataset that only yields raw text inputs (no labels).\n",
        "text_vectorization.adapt(text_only_train_ds) #Use that dataset to index the dataset vocabulary via the adapt() method\n",
        "\n",
        "binary_1gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),num_parallel_calls=4) #Prepare processed versions of our training,\n",
        "binary_1gram_val_ds = val_ds.map(                                 #validation, and test dataset.\n",
        "    lambda x, y: (text_vectorization(x), y),num_parallel_calls=4) #Make sure to specify num_parallel_calls\n",
        "binary_1gram_test_ds = test_ds.map(                               #to leverage multiple CPU cores.\n",
        "    lambda x, y: (text_vectorization(x), y),num_parallel_calls=4) # o resultado de lambda mapeia x,y em vetor multi-hot,y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn-URID5grfm"
      },
      "source": [
        "Inspecting the output of our binary unigram dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV6lSB4Agsb-",
        "outputId": "71b5c8da-d509-499e-e63d-9e2d44d66c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32, 20000)\n",
            "inputs.dtype: <dtype: 'int64'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor([1 0 1 ... 0 0 0], shape=(20000,), dtype=int64)\n",
            "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in binary_1gram_train_ds:\n",
        "  print(\"inputs.shape:\", inputs.shape)   #Inputs are batches of 20,000-dimensional vectors.\n",
        "  print(\"inputs.dtype:\", inputs.dtype)   #These vectors consistentirely of ones and zeros.\n",
        "  print(\"targets.shape:\", targets.shape)\n",
        "  print(\"targets.dtype:\", targets.dtype)\n",
        "  print(\"inputs[0]:\", inputs[0])\n",
        "  print(\"targets[0]:\", targets[0])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-8Ztl9Xix3x"
      },
      "source": [
        "Criando um modelo simples de classificação com uma camada escondida e uma camada de saída. Funções ReLU e sigmmoid. Usa Dropout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mdBwJGPni-3N"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "v4wKcH6WSdWy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oGHnjpwPjXRJ"
      },
      "outputs": [],
      "source": [
        "def get_model(max_tokens=20000, hidden_dim=16):\n",
        "    inputs = keras.Input(shape=(max_tokens,))\n",
        "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUZG7YLzju6W"
      },
      "source": [
        "Treinando o modelo (We call cache() on the datasets to cache them in memory: this way, we will only do the preprocessing once, during the first epoch, and we’ll reuse the preprocessed texts for the following epochs. This can only be done if the data is small enough to fit in memory.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "DuDm32M8j1Xa",
        "outputId": "5f08dfb5-3ee2-47a8-f10c-e44aafdff19f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │       \u001b[38;5;34m320,016\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,016</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.7616 - loss: 0.4934 - val_accuracy: 0.8810 - val_loss: 0.3026\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8815 - loss: 0.2985\n",
            "Test accuracy: 0.883\n"
          ]
        }
      ],
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "\n",
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath + '.weights.h5',  # adiciona a extensão correta\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    binary_1gram_train_ds,\n",
        "    validation_data=binary_1gram_val_ds.cache(),\n",
        "    epochs=1,\n",
        "    callbacks=[model_checkpoint_callback]\n",
        ")\n",
        "\n",
        "# Carrega pesos do arquivo correto\n",
        "model.load_weights(checkpoint_filepath + '.weights.h5')\n",
        "\n",
        "# Avalia\n",
        "test_loss, test_acc = model.evaluate(binary_1gram_test_ds)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FztIREmpEoV"
      },
      "source": [
        "\"********************************************************\"-\n",
        "****O código a Seguir refere-se a \"*TextVectorization_bag_bigram\"****\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnWT3tghpRiC"
      },
      "source": [
        "TheTextVectorizationlayer can be configured to return arbitrary N-grams: bigrams,trigrams, etc. Just pass anngrams=Nargument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUhJNjwKpHDl"
      },
      "outputs": [],
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"multi_hot\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwzTwqVppbd5"
      },
      "source": [
        "Training and testing the binary bigram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4IAvWsapcgk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)  #Prepare a dataset that only yields raw text inputs (no labels).\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "binary_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),num_parallel_calls=4)\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),num_parallel_calls=4)\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),num_parallel_calls=4)\n",
        "model = get_model()\n",
        "model.summary()\n",
        "\n",
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/tmp/checkpoint.weights.h5',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "#callbacks = [\n",
        "#    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",save_best_only=True)\n",
        "#]\n",
        "\n",
        "model.fit(binary_2gram_train_ds.cache(),\n",
        "validation_data=binary_2gram_val_ds.cache(),\n",
        "epochs=1,callbacks=[model_checkpoint_callback]\n",
        ")\n",
        "#model = keras.models.load_model(\"binary_2gram.keras\")\n",
        "model.load_weights(checkpoint_filepath)\n",
        "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS1obpoWexER"
      },
      "outputs": [],
      "source": [
        "print(f\"Test acc: {model.evaluate(binary_2gram_val_ds)[1]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2Mp257fdrov"
      },
      "source": [
        "***Tarefa para os alunos: implementar com tf_idf**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}